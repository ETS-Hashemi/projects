# ğŸ§  Seyed Masoud Hashemi Ahmadi â€” Ongoing AI Research Projects

This repository documents and organizes the set of high-impact, novel research projects I am currently developing in the area of **symbolic reasoning**, **probabilistic logic**, and **explainable intelligent agents**.

All projects are being developed in **Python**, with a focus on **educational value**, **open scientific contribution**, and **real-world decision support applications**.

---

## ğŸ“Š Project Landscape Summary

| Extension | Academic Maturity | Novelty Today | Python Open Implementation | Publication Chance |
|----------|-------------------|----------------|------------------------------|---------------------|
| **Temporal Logic (LTL/CTL) Agents** | Rare in education, moderate in theory | â˜…â˜…â˜…â˜…â˜† | Almost none | ğŸ”¥ **HIGH** |
| **First-Order Logic (FOL) Agent** | Common in theory, rare in practical CS | â˜…â˜…â˜…â˜†â˜† | Very few tools | âš–ï¸ **MEDIUM** |
| **Probabilistic Logic Agents** *(active)* | Active research (PGMs), but not integrated with symbolic KBs well | â­â­â­â­â­ | Very rare in symbolic+probabilistic blend | ğŸš€ **VERY HIGH** |
| **Multi-Agent KB System with Communication** | Explored conceptually, almost no educational tools | â­â­â­â­â­ | Not done in Python for education | ğŸš€ **VERY HIGH** |
| **XAI for Logical Reasoning (Traceable Inference)** | Talked about, few visual tools | â­â­â­â­â˜† | Basically none exist | ğŸ”¥ **HIGH** |
| **Hybrid Symbolic-Neural KB Agents** | Hot area, hard to do cleanly | â­â­â­â˜†â˜† | Some experiments, no educational examples | âš–ï¸ **MEDIUM** |

---

## ğŸ“‚ Current Work

### ğŸ”· [`PLA/`](./PLA) â€” Probabilistic Logic Agent Framework (active)

> A novel Python-based framework that integrates symbolic propositional logic with probabilistic reasoning, enabling agents to reason under uncertainty with full traceability and modular design.

- Combines logic rules (e.g. `A âˆ§ B â†’ C`) with probabilistic weights (`0.9`)
- Designed for domains such as auditing, law, and AI safety
- Fully explainable inference
- Modular, human-readable, educational architecture
- Will be published under Apache License

ğŸ“Œ **Status**: Architecture complete, core engine under construction  
ğŸ“… **Goal**: Research paper submission by Juneâ€“July 2025

---

## ğŸ§  Upcoming Projects (Planned)

### ğŸ•’ `TemporalLogicAgent/`
- Agent that reasons about sequences of events over time using LTL/CTL
- Ideal for decision systems where *eventual* truths or obligations matter (e.g., planning, compliance)
- Will include time-step-based KB, temporal model checker, and interactive visualization

ğŸ“Œ **Planned start**: Summer 2025  
ğŸ¯ **Target**: ICAPS or KR workshops

---

### ğŸ§  `FOLAgent/`
- First-order logic agent with support for variables, quantifiers (`âˆ€`, `âˆƒ`), and substitution
- Aims to fill the educational tooling gap for teaching FOL inference in Python
- Possibly extendable to resolution or unification-based theorem proving

ğŸ“Œ **Planned start**: Fall 2025  
ğŸ¯ **Target**: Education or AI logic workshops

---

### ğŸ§  `MultiAgentKB/`
- A multi-agent system where agents each hold independent KBs
- Supports rule exchange, belief negotiation, and consistency checks
- Agents may disagree, revise beliefs, or follow authority weighting
- Ideal for research in distributed reasoning and argumentation

ğŸ“Œ **Planned start**: Q3 2025  
ğŸ¯ **Target**: AAMAS, JAAMAS, or RuleML

---

### ğŸ§  `XAI-Logic-Explainer/`
- Visualization layer to add **traceability** to all symbolic or probabilistic logic agents
- Converts inference steps into readable chains or graphs using `networkx` or `Graphviz`
- Enables human-centered audits and debug views of decision logic

ğŸ“Œ **Planned start**: Q2 2025  
ğŸ¯ **Target**: AI & Society or Explainable AI venues

---

### ğŸ§  `NeuroSymbolic-KB/`
- Exploration into combining neural embedding models (e.g., BERT) with symbolic rules
- Goal is to enrich symbolic rules with latent features and improve recall
- Could be used for hybrid document reasoning or semi-structured inference

ğŸ“Œ **Planned start**: TBD (dependent on compute resources)  
ğŸ¯ **Target**: NeSy, NeurIPS workshop, or ECAI

---

## ğŸ“„ License

All code is licensed under the **Apache License 2.0**, unless otherwise noted.

---

##  Academic Attribution

This project is developed as part of the PhD research of  
**Seyed Masoud Hashemi Ahmadi**  
at **Ã‰cole de technologie supÃ©rieure (Ã‰TS), MontrÃ©al**.

If you use this work in academic research, citation is appreciated.


ğŸ“¬ [contact@AiCentralLab.com](mailto:contact@AiCentralLab.com)

---

## ğŸ” Repository Status

- Current repositories are **private** due to research novelty
- To be made public following publication or preprint submission
- GitHub branch protection, 2FA, and backup repositories in place

---

## ğŸ“… Timeline

| Phase | Dates | Description |
|-------|-------|-------------|
| **PLA Core Engine** | Aprâ€“May 2025 | Base logic + probabilistic inference |
| **PLA Evaluation** | Jun 2025 | Benchmarks + use cases (audit, med, legal) |
| **Paper Draft & Submission** | Jul 2025 | RuleML, IJCAI, or XAI workshops |
| **Temporal Logic Agent Start** | Summer 2025 | Model checker with LTL |
| **FOL Agent Build** | Fall 2025 | Unification + resolution |
| **Multi-Agent System** | Q3 2025 | Agent interaction logic |
| **Traceable XAI Layer** | Ongoing | Shared across all projects |

---

## ğŸ“Œ Goals

- Deliver the **first lightweight Python framework** combining symbolic logic with uncertainty
- Make logical AI **explainable, teachable, and applicable**
- Publish multiple **modular research agents** for auditing, safety, and reasoning under uncertainty

---

