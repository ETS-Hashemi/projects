# Probabilistic Logic Agent Framework

## Overview

The **Probabilistic Logic Agent Framework** is a Python-based system that integrates **symbolic propositional logic** with **probabilistic reasoning**. It enables reasoning in **uncertain environments** using **weighted logical rules** to infer probabilistic outcomes. Designed for **explainability** and **modularity**, this framework is ideal for domains like auditing, legal reasoning, medical AI, and decision support systems.

---

## Motivation

Real-world decisions often involve uncertainty, such as:
> "If A and B, then probably C."

Existing AI systems force a choice between:
- **Symbolic logic**: Explainable but rigid and not uncertainty-aware.
- **Probabilistic models**: Flexible but opaque and not rule-driven.

This framework bridges the gap by combining **rules with probabilities**, enabling agents to answer **what they believe**, **how confident they are**, and **why**.

---

## What Makes This Different?

| **Feature**       | **This Project**                     | **CS50AI Logic Agents** | **Markov Logic Networks (MLNs)** | **Bayesian Networks** | **Black-Box AI / ML** |
|--------------------|--------------------------------------|--------------------------|-----------------------------------|------------------------|------------------------|
| **Logic Type**     | **Propositional logic + probabilities** | Propositional only      | First-order logic                | None                   | None                   |
| **Explainability** | âœ… Full reasoning trace             | âœ…                       | âŒ (sampling-based)               | âŒ (graph traversal)    | âŒ                     |
| **Language**       | **Pure Python**                     | Python                  | Prolog / Alchemy / Java           | Python (pgmpy)         | Python                 |
| **Inference**      | **Model checking + probabilistic scoring** | Model checking         | MRF sampling                     | Variable elimination   | Gradient descent       |
| **Data Requirement** | âœ… Works with few rules            | âœ…                       | âŒ Needs grounding                | âŒ Graphs must be trained | âŒ Requires large data |
| **Modifiability**  | âœ… Simple rule editing              | âœ…                       | âŒ Complex template structure     | âŒ Inflexible           | âŒ                     |
| **Use Case**       | Decision support, explainable AI    | Learning logic          | Large knowledge graphs            | Probabilistic causality | Pattern recognition    |

âœ… **This is not an MLN, not a BN, and not just CS50AI with tweaks.**  
It is a new, hybrid symbolic-probabilistic framework for **explainable inference in uncertain environments.**

---

## Features

- Define rules like `"If A and B â†’ C (0.9)"`.
- Add facts to a knowledge base and query for probabilities.
- Trace all rule activations and logic chains for full explainability.
- Lightweight, modular architecture with no heavy dependencies.
- Works in low-data environments and supports easy rule editing.

---

## Installation

```
git clone https://github.com/YOUR_USERNAME/probabilistic-logic-agent.git
cd probabilistic-logic-agent
pip install -r requirements.txt
```

> ðŸ“Œ **Note**: This repository is private during development for novelty protection.

---

## Example Usage

```python
from prob_agent import ProbSymbol, ProbRule, ProbKB, InferenceEngine

# Define symbols
large = ProbSymbol("LargeTransaction")
no_receipt = ProbSymbol("NoReceipt")
fraud = ProbSymbol("Fraud")

# Define a probabilistic rule
rule1 = ProbRule(
    condition=[large, no_receipt],
    result=fraud,
    probability=0.85
)

# Set up the knowledge base
kb = ProbKB()
kb.add_fact(large)
kb.add_fact(no_receipt)
kb.add_rule(rule1)

# Query the KB
engine = InferenceEngine(kb)
prob, explanation = engine.query(fraud)

print(f"P(Fraud) = {prob}")
print("Explanation:")
print(explanation)
```

---

## Applications

- **Auditing & Accounting**: Fraud detection using rules like "Large transaction + no receipt = suspicious."
- **Legal Reasoning**: Evaluate liability or guilt from structured case facts.
- **Medical Diagnosis**: Diagnose based on symptoms with known probabilities.
- **Educational AI**: Infer student understanding from indirect indicators.
- **AI Governance**: Rule-aware, safe agents for decision support.

---

## Planned Architecture

```
prob_agent/
â”‚
â”œâ”€â”€ symbols.py            # ProbSymbol class
â”œâ”€â”€ rules.py              # ProbRule class
â”œâ”€â”€ knowledge_base.py     # ProbKB class
â”œâ”€â”€ inference.py          # InferenceEngine class
â”œâ”€â”€ explanation.py        # Tracks reasoning chains
â”œâ”€â”€ examples/             # Jupyter notebooks and real-world tests
â”œâ”€â”€ tests/                # Unit tests
â””â”€â”€ README.md             # Project documentation
```

---

## Roadmap

### Phase 1: Core Framework
- [x] Implement `ProbSymbol`, `ProbRule`, `ProbKB`.
- [x] Build inference engine with model checking.
- [x] Add traceable explanations.

### Phase 2: Modular Extensions
- [ ] Add forward chaining and probabilistic facts.
- [ ] Integrate `pgmpy` or `pomegranate` for advanced inference.
- [ ] Optimize performance for large rule sets.

### Phase 3: Evaluation
- [ ] Benchmark in domains like auditing, medical, and legal reasoning.
- [ ] Collect feedback on transparency and usability.

### Phase 4: Publication
- [ ] Write research paper for venues like IJCAI or RuleML.
- [ ] Prepare polished GitHub repo and Colab demo.

---

## License

Licensed under the **Apache License 2.0**.  
Â© 2025 Seyed Masoud Hashemi Ahmadi.

---

## Contact

For collaboration or inquiries:  
ðŸ“§ [contact@AiCentralLab.com](mailto:contact@AiCentralLab.com)

